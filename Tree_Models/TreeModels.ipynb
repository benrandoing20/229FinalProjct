{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees for AD severity classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3427888156.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [52]\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install scikit-learn\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Make sure to install these libraries (one by one)pip install pandas\n",
    "pip install scikit-learn\n",
    "pip install xgboost\n",
    "pip install matplotlib\n",
    "pip install mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import mahotas as mh  # Import the mahotas library for texture feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (from preprocessing.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file 'dataset.csv' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Directory to MRI Images\n",
    "data_dir = 'data/AugmentedAlzheimerDataset'\n",
    "classes = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "\n",
    "if not os.path.exists('dataset.csv'):\n",
    "    # Your code to generate dataset.csv goes here\n",
    "    data = []\n",
    "\n",
    "    for label, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for image_name in os.listdir(class_dir):\n",
    "            image_path = os.path.join(class_dir, image_name)\n",
    "            data.append([image_path, label])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['path', 'label'])\n",
    "    df.to_csv('dataset.csv', index=False)\n",
    "    print(\"CSV file 'dataset.csv' has been created.\")\n",
    "else:\n",
    "    print(\"The CSV file 'dataset.csv' already exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        self.dataframe = self.dataframe.sample(frac=1).reset_index(drop=True)  # Shuffle the dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx, 0]\n",
    "        image = Image.open(img_name)\n",
    "        label = int(self.dataframe.iloc[idx, 1])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define a transformation for the CNN model (resize, normalize, etc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to match the input size of the pre-trained model\n",
    "    transforms.ToTensor(),  # Convert image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet statistics\n",
    "])\n",
    "\n",
    "# Load the entire dataset\n",
    "dataset = CustomDataset(csv_file='dataset.csv', transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 28886\n",
      "Test Samples: 5098\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_size = int(0.85 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset,  test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "print(f'Training Samples: {len(train_dataset)}')\n",
    "print(f'Test Samples: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader objects for training, validation, and test datasets\n",
    "# batch_size = 64  # Adjust the batch size as needed\n",
    "# train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to accumulate the data\n",
    "data_accumulator = []\n",
    "\n",
    "# Loop through the train_dataset to extract data\n",
    "for idx in range(len(train_dataset)):\n",
    "    image, label = train_dataset[idx]\n",
    "    data_accumulator.append([image, label])\n",
    "\n",
    "# Create a DataFrame from the accumulated data\n",
    "train_df = pd.DataFrame(data_accumulator, columns=['image', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['image'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction - method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract texture features from an image\n",
    "def extract_texture_features(image):\n",
    "    # Convert the image tensor to a NumPy array\n",
    "    image_np = (image.numpy() * 255).astype(np.uint8)\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = np.mean(image_np, axis=0).astype(np.uint8)\n",
    "    # Compute Haralick texture features\n",
    "    texture_features = mh.features.haralick(image_gray)\n",
    "\n",
    "    return texture_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texture_features = []\n",
    "\n",
    "for idx in range(len(train_df)):\n",
    "    image, label = train_df.iloc[idx]\n",
    "    texture_features = extract_texture_features(image)\n",
    "    train_texture_features.append(texture_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = [image.reshape(-1) for image in train_df['image']]\n",
    "X_train = np.array(feature_vectors)\n",
    "y_train = train_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction - other method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "# Replace 'local_path_to_resnet50.pth' with the path to your downloaded model checkpoint\n",
    "checkpoint_path = '/Users/annabel/iCloudÂ Drive (archive)/Desktop/Stanford/CS229/project/resnet50-19c8e357.pth'\n",
    "\n",
    "# Load the ResNet-50 model from the local checkpoint file\n",
    "resnet_model = resnet50(pretrained=False)  # Set 'pretrained' to False because you're using a custom checkpoint\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "resnet_model.load_state_dict(checkpoint)\n",
    "resnet_model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store extracted features and labels\n",
    "extracted_features = []\n",
    "labels = []\n",
    "\n",
    "# Loop through the DataFrame\n",
    "for idx, row in train_df.iterrows():\n",
    "    image_tensor = row['image']\n",
    "    label = row['label']\n",
    "    if idx%1000==0:\n",
    "        print(idx)\n",
    "\n",
    "    # Pass the image tensor through the ResNet-50 model to extract features\n",
    "    with torch.no_grad():\n",
    "        features = resnet_model(image_tensor.unsqueeze(0))\n",
    "\n",
    "    # Convert the features to a NumPy array\n",
    "    features_np = features.squeeze().numpy()\n",
    "\n",
    "    # Append the features and label to the respective lists\n",
    "    extracted_features.append(features_np)\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "features_array_from_df = np.array(extracted_features)\n",
    "labels_array_from_df = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28886, 1000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array_from_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these features into csv file\n",
    "resnet50_features_train_df = pd.DataFrame(features_array_from_df, columns=[f'feature_{i}' for i in range(features_array_from_df.shape[1])])\n",
    "resnet50_features_train_df['label'] = labels_array_from_df\n",
    "resnet50_features_train_df.to_csv('resnet50_feat_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss  # Import log_loss metric\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('resnet50_feat_train.csv')\n",
    "features_array_from_df = df.iloc[:, :-1].values\n",
    "labels_array_from_df = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71155214, -0.38360843, -1.455084  , ..., -0.0142841 ,\n",
       "        -0.06864337,  1.0355113 ],\n",
       "       [ 1.1589302 , -0.6699271 , -2.224792  , ...,  1.4010689 ,\n",
       "         1.0879478 , -0.70630056],\n",
       "       [ 1.3018154 , -0.20744719, -3.1274955 , ...,  3.201485  ,\n",
       "         1.7387248 , -1.597165  ],\n",
       "       ...,\n",
       "       [ 0.5856775 , -0.36300635, -2.8009105 , ...,  1.411801  ,\n",
       "         1.1639006 , -1.0536482 ],\n",
       "       [ 1.5801008 ,  0.08003613, -2.7768729 , ...,  2.195241  ,\n",
       "         1.6303772 , -1.7860281 ],\n",
       "       [ 1.3432102 , -0.41527712, -1.8111019 , ...,  1.1150697 ,\n",
       "         0.72649693, -0.23272035]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array_from_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 4,\n",
    "    'eval_metric': 'mlogloss', \n",
    "    'max_depth': 10, \n",
    "    'eta': 0.2\n",
    "}\n",
    "\n",
    "# Create DMatrix for your data\n",
    "dtrain = xgb.DMatrix(features_array_from_df, label=labels_array_from_df)\n",
    "\n",
    "# Set the number of boosting rounds\n",
    "num_round = 100\n",
    "\n",
    "# Initialize a list to store cross-validation results\n",
    "cv_results = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_folds = 5  # You can adjust this value as needed\n",
    "\n",
    "# Initialize a StratifiedKFold splitter\n",
    "kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store confusion matrices for each fold\n",
    "confusion_matrices = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(features_array_from_df, labels_array_from_df):\n",
    "    X_train_fold, X_val_fold = features_array_from_df[train_index], features_array_from_df[val_index]\n",
    "    y_train_fold, y_val_fold = labels_array_from_df[train_index], labels_array_from_df[val_index]\n",
    "\n",
    "    dtrain_fold = xgb.DMatrix(X_train_fold, label=y_train_fold)\n",
    "    dval_fold = xgb.DMatrix(X_val_fold, label=y_val_fold)\n",
    "\n",
    "    # Train the model\n",
    "    model = xgb.train(params, dtrain_fold, num_round, evals=[(dval_fold, 'eval')], early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "    # Make predictions on the validation fold\n",
    "    y_pred = model.predict(dval_fold)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_val_fold, y_pred)\n",
    "\n",
    "    # Append the confusion matrix to the list\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "\n",
    "    cv_results.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7874749794080235\n",
      "Standard Deviation: 0.0028137884385134077\n",
      "Overall Confusion Matrix:\n",
      "[[6354  140  369  763]\n",
      " [ 103 5281   20   81]\n",
      " [ 756   75 6123 1210]\n",
      " [1029  160 1433 4989]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation of cross-validation results\n",
    "mean_accuracy = np.mean(cv_results)\n",
    "std_accuracy = np.std(cv_results)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation: {std_accuracy}\")\n",
    "\n",
    "# Combine all confusion matrices into a single matrix\n",
    "overall_confusion_matrix = np.sum(confusion_matrices, axis=0)\n",
    "\n",
    "print(\"Overall Confusion Matrix:\")\n",
    "print(overall_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model into pkl file\n",
    "\n",
    "import pickle\n",
    "\n",
    "model_file = 'xgboost_model.pkl' \n",
    "with open(model_file, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Feature Importance Visualization\n",
    "# Plot feature importance\n",
    "plot_importance(model)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to accumulate the data\n",
    "data_accumulator = []\n",
    "\n",
    "# Loop through the test_dataset to extract data\n",
    "for idx in range(len(test_dataset)):\n",
    "    image, label = test_dataset[idx]\n",
    "    data_accumulator.append([image, label])\n",
    "\n",
    "# Create a DataFrame from the accumulated data\n",
    "test_df = pd.DataFrame(data_accumulator, columns=['image', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "# Replace 'local_path_to_resnet50.pth' with the path to your downloaded model checkpoint\n",
    "checkpoint_path = '/Users/annabel/iCloudÂ Drive (archive)/Desktop/Stanford/CS229/project/resnet50-19c8e357.pth'\n",
    "\n",
    "# Load the ResNet-50 model from the local checkpoint file\n",
    "model = resnet50(pretrained=False)  # Set 'pretrained' to False because you're using a custom checkpoint\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store extracted features and labels\n",
    "extracted_features = []\n",
    "labels = []\n",
    "\n",
    "# Loop through the DataFrame\n",
    "for idx, row in test_df.iterrows():\n",
    "    image_tensor = row['image']\n",
    "    label = row['label']\n",
    "    if idx%1000==0:\n",
    "        print(idx)\n",
    "\n",
    "    # Pass the image tensor through the ResNet-50 model to extract features\n",
    "    with torch.no_grad():\n",
    "        features = model(image_tensor.unsqueeze(0))\n",
    "\n",
    "    # Convert the features to a NumPy array\n",
    "    features_np = features.squeeze().numpy()\n",
    "\n",
    "    # Append the features and label to the respective lists\n",
    "    extracted_features.append(features_np)\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "features_array_test = np.array(extracted_features)\n",
    "labels_array_test = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 2, 0, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_array_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these features into csv file\n",
    "resnet50_features_test_df = pd.DataFrame(features_array_test, columns=[f'feature_{i}' for i in range(features_array_test.shape[1])])\n",
    "resnet50_features_test_df['label'] = labels_array_test\n",
    "resnet50_features_test_df.to_csv('resnet50_feat_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To load the model \n",
    "\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the saved model from a file\n",
    "model_file = 'xgboost_model.pkl'  # Replace with the path to your saved model file\n",
    "\n",
    "with open(model_file, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Now, 'loaded_model' contains the XGBoost model loaded from the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/annabel/iCloudÂ Drive (archive)/Desktop/Stanford/CS229/project/229FinalProject/TreeModels.ipynb Cellule 38\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/annabel/iCloud%C2%A0Drive%20%28archive%29/Desktop/Stanford/CS229/project/229FinalProject/TreeModels.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dtest \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mDMatrix(features_array_test, label\u001b[39m=\u001b[39mlabels_array_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/annabel/iCloud%C2%A0Drive%20%28archive%29/Desktop/Stanford/CS229/project/229FinalProject/TreeModels.ipynb#X63sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/annabel/iCloud%C2%A0Drive%20%28archive%29/Desktop/Stanford/CS229/project/229FinalProject/TreeModels.ipynb#X63sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m y_pred_test \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49mpredict(dtest)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/annabel/iCloud%C2%A0Drive%20%28archive%29/Desktop/Stanford/CS229/project/229FinalProject/TreeModels.ipynb#X63sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Calculate the confusion matrix\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/annabel/iCloud%C2%A0Drive%20%28archive%29/Desktop/Stanford/CS229/project/229FinalProject/TreeModels.ipynb#X63sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_pred_test, labels_array_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1184\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1185\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1186\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(features_array_test, label=labels_array_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = loaded_model.predict(dtest)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_pred_test, labels_array_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_pred_test, labels_array_test)\n",
    "\n",
    "print(accuracy)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: oops I rerun the cell and should have, but the test accuracy was 0.78. You could train the model again, but it will take a few minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further improvements:\n",
    "1. Try with log loss metric\n",
    "2. Run grid search for XGB using the ResNet50 features\n",
    "3. Try other feature extraction methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
